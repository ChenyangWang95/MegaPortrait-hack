data:
  # train_width: 256 
  # train_height: 256 
  # sample_rate: 25 
  # n_sample_frames: 1
  # n_motion_frames: 2
  root_dir: '/workspace/data/celebavhq'
  frame_shape: [256, 256, 3]
  id_sampling: False
  pairs_list: None
  augmentation_params:
    flip_param:
      horizontal_flip: True
      time_flip: True
    jitter_param:
      brightness: 0.1
      contrast: 0.1
      saturation: 0.1
      hue: 0.1
    resize_param: 
      size: [256, 256]


training:
  save_interval: 30
  log_interval: 5
  lambda_perceptual: 1.0
  lambda_adversarial: 1.0
  lambda_cosine: 1.0
  lambda_keypoints: 1.0
  lambda_gaze: 1.0
  lambda_supervised: 1.0
  lambda_unsupervised: 1.0
  batch_size: 2
  num_workers: 8
  lr: 1.0e-5
  base_epochs: 200000
  hr_epochs: 50
  student_epochs: 100
  use_gpu_video_tensor: True
  prev_frames: 2  # Add this line to specify the number of previous frames to consider
  video_dir:  'junk'
  sample_rate: 25  
  n_sample_frames: 100
  json_file: './data/overfit.json'
  
  w_per: 1  # perceptual loss
  w_adv: 1   # adversarial loss
  w_fm: 40   # feature matching loss
  w_cos: 2   # cycle consistency loss

